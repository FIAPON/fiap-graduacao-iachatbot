{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução à Regressão Logística\n",
    "\n",
    "A Regressão Logística é um algoritmo de aprendizado de máquina supervisionado amplamente utilizado para problemas de classificação binária. Diferentemente da regressão linear, que prevê valores contínuos, a regressão logística estima a probabilidade de uma instância pertencer a uma classe específica. Ela utiliza a função sigmoide para mapear valores de qualquer escala para um intervalo entre 0 e 1, permitindo interpretar a saída como uma probabilidade.\n",
    "\n",
    "## Conceitos Fundamentais:\n",
    "\n",
    "* Função Sigmoide: Transforma a saída linear em uma probabilidade entre 0 e 1.\n",
    "* Coeficientes: Representam a influência de cada variável independente na probabilidade do evento.\n",
    "* Logit: É o logaritmo da razão de chances (odds ratio) e é a saída linear da regressão logística.\n",
    "\n",
    "---\n",
    "\n",
    "# Introdução ao Dataset\n",
    "\n",
    "Para este projeto, utilizaremos o Dataset de Câncer de Mama disponível no módulo sklearn.datasets da biblioteca Scikit-Learn. Este conjunto de dados é amplamente utilizado para problemas de classificação binária em aprendizado de máquina, especialmente na área médica, para prever se um tumor é maligno ou benigno com base em características extraídas de imagens digitais de massas mamárias.\n",
    "Descrição do Dataset:\n",
    "\n",
    "* Objetivo: Prever se um tumor é maligno ou benigno.\n",
    "* Atributos: O dataset contém 569 amostras com 30 características numéricas calculadas a partir de imagens digitais de células aspiradas por agulha fina de uma massa mamária.\n",
    "* Variável Alvo: target (0 = maligno, 1 = benigno).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação das Bibliotecas Necessárias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuração do estilo dos gráficos\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CARREGAMENTO DO DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Carregar o dataset de câncer de mama\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# Criar um DataFrame com os dados\n",
    "df = pd.DataFrame(data=cancer.data, columns=cancer.feature_names)\n",
    "df['target'] = cancer.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANÁLISE EXPLORATÓRIA DE DADOS (AED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização das primeiras entradas do dataset\n",
    "print(\"Visualização das primeiras 5 entradas do dataset:\")\n",
    "display(df.head())\n",
    "\n",
    "# Informações gerais sobre o dataset\n",
    "print(\"\\nInformações gerais do dataset:\")\n",
    "df.info()\n",
    "\n",
    "# Estatísticas descritivas do dataset\n",
    "print(\"\\nEstatísticas descritivas do dataset:\")\n",
    "display(df.describe())\n",
    "\n",
    "# Verificação de valores nulos\n",
    "print(\"\\nVerificação de valores nulos:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Distribuição da variável alvo\n",
    "sns.countplot(x='target', data=df)\n",
    "plt.title('Distribuição das Classes da Variável Alvo')\n",
    "plt.xlabel('Target (0 = Maligno, 1 = Benigno)')\n",
    "plt.ylabel('Contagem')\n",
    "plt.show()\n",
    "\n",
    "# Observação sobre o balanceamento das classes\n",
    "print(\"\\nContagem de classes:\")\n",
    "print(df['target'].value_counts())\n",
    "\n",
    "# Análise de correlação\n",
    "plt.figure(figsize=(12,10))\n",
    "corr = df.corr()\n",
    "sns.heatmap(corr, annot=False, cmap='coolwarm')\n",
    "plt.title('Mapa de Calor das Correlações entre as Variáveis')\n",
    "plt.show()\n",
    "\n",
    "# Seleção das características mais correlacionadas com a variável alvo\n",
    "print(\"\\nCorrelação das características com a variável alvo:\")\n",
    "corr_target = abs(corr[\"target\"].drop('target'))\n",
    "print(corr_target.sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARAÇÃO DOS DADOS PARA O MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação das Variáveis Independentes (X) e Dependente (y)\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Divisão dos Dados em Conjuntos de Treino e Teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Usando stratify=y para manter a proporção das classes nos conjuntos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Verificação das dimensões dos conjuntos\n",
    "print(f\"\\nDimensão do conjunto de treino: {X_train.shape}\")\n",
    "print(f\"Dimensão do conjunto de teste: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NORMALIZAÇÃO DOS DADOS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Criação do objeto StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajuste do scaler apenas nos dados de treino\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Aplicação da transformação nos dados de teste\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TREINAMENTO DO MODELO DE REGRESSÃO LOGÍSTICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Criação do modelo de regressão logística\n",
    "logreg = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# Treinamento do modelo com os dados de treino escalonados\n",
    "logreg.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AVALIAÇÃO DO MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "# Previsões nos dados de teste\n",
    "y_pred = logreg.predict(X_test_scaled)\n",
    "y_pred_proba = logreg.predict_proba(X_test_scaled)[:,1]\n",
    "\n",
    "# Relatório de classificação do modelo\n",
    "print(\"\\nRelatório de Classificação (Modelo Padrão):\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Matriz de confusão\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Matriz de Confusão (Modelo Padrão)')\n",
    "plt.ylabel('Verdadeiro')\n",
    "plt.xlabel('Previsto')\n",
    "plt.show()\n",
    "\n",
    "# Curva ROC e AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr, tpr, label='AUC = %.2f' % auc)\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlabel('Taxa de Falso Positivo')\n",
    "plt.ylabel('Taxa de Verdadeiro Positivo')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AJUSTE DE HIPERPARÂMETROS COM GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definição da grade de parâmetros a serem testados\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'solver': ['lbfgs', 'liblinear'],\n",
    "    'penalty': ['l2']\n",
    "}\n",
    "\n",
    "# Criação do objeto GridSearchCV\n",
    "grid = GridSearchCV(LogisticRegression(max_iter=10000), param_grid, refit=True, verbose=2, cv=5)\n",
    "\n",
    "# Ajuste do GridSearchCV aos dados de treino\n",
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULTADOS DO GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor estimador e parâmetros encontrados\n",
    "print(\"\\nMelhores Parâmetros Encontrados pelo GridSearchCV:\")\n",
    "print(grid.best_params_)\n",
    "print(\"\\nMelhor Estimador:\")\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AVALIAÇÃO DO MODELO OTIMIZADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões com o melhor modelo encontrado\n",
    "grid_predictions = grid.predict(X_test_scaled)\n",
    "grid_predictions_proba = grid.predict_proba(X_test_scaled)[:,1]\n",
    "\n",
    "# Relatório de classificação do modelo otimizado\n",
    "print(\"\\nRelatório de Classificação (Modelo Otimizado):\")\n",
    "print(classification_report(y_test, grid_predictions))\n",
    "\n",
    "# Matriz de confusão para o modelo otimizado\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(confusion_matrix(y_test, grid_predictions), annot=True, fmt='d', cmap='Greens')\n",
    "plt.title('Matriz de Confusão (Modelo Otimizado)')\n",
    "plt.ylabel('Verdadeiro')\n",
    "plt.xlabel('Previsto')\n",
    "plt.show()\n",
    "\n",
    "# Curva ROC e AUC para o modelo otimizado\n",
    "fpr, tpr, thresholds = roc_curve(y_test, grid_predictions_proba)\n",
    "auc = roc_auc_score(y_test, grid_predictions_proba)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr, tpr, label='AUC = %.2f' % auc)\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlabel('Taxa de Falso Positivo')\n",
    "plt.ylabel('Taxa de Verdadeiro Positivo')\n",
    "plt.title('Curva ROC (Modelo Otimizado)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SALVANDO O MODELO PARA DEPLOY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Salvando o melhor modelo encontrado pelo GridSearchCV\n",
    "joblib.dump(grid.best_estimator_, 'logreg_cancer_model.pkl')\n",
    "\n",
    "# Salvando o scaler para uso futuro na normalização de novos dados\n",
    "joblib.dump(scaler, 'scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMO FAZER UMA PREDIÇÃO INÉDITA COM O MODELO SALVO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o modelo e o scaler salvos\n",
    "model = joblib.load('logreg_cancer_model.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# Novo dado para predição (exemplo fictício)\n",
    "# As características devem estar na mesma ordem que no conjunto de treinamento\n",
    "import numpy as np\n",
    "new_data = np.array([[14.0,20.0,90.0,600.0,0.1,0.2,0.3,0.15,0.2,0.05,\n",
    "                      0.4,1.5,2.5,40.0,0.005,0.03,0.04,0.01,0.02,0.004,\n",
    "                      16.0,25.0,110.0,800.0,0.15,0.4,0.5,0.2,0.3,0.08]])\n",
    "\n",
    "# Escalar o novo dado usando o scaler carregado\n",
    "new_data_scaled = scaler.transform(new_data)\n",
    "\n",
    "# Fazer a predição com o modelo carregado\n",
    "prediction = model.predict(new_data_scaled)\n",
    "prediction_proba = model.predict_proba(new_data_scaled)[:,1]\n",
    "\n",
    "# Interpretar o resultado\n",
    "if prediction[0] == 0:\n",
    "    print(\"\\nO modelo prevê que o tumor é MALIGNO.\")\n",
    "else:\n",
    "    print(\"\\nO modelo prevê que o tumor é BENIGNO.\")\n",
    "\n",
    "print(f\"Probabilidade de ser benigno: {prediction_proba[0]*100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
